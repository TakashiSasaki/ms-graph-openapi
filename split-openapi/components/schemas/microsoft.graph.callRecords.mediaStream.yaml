title: mediaStream
required:
  - '@odata.type'
type: object
properties:
  audioCodec:
    anyOf:
      - $ref: .\microsoft.graph.callRecords.audioCodec.yaml
      - type: object
        nullable: true
    description: >-
      Codec name used to encode audio for transmission on the network. Possible
      values are: unknown, invalid, cn, pcma, pcmu, amrWide, g722, g7221,
      g7221c, g729, multiChannelAudio, muchv2, opus, satin, satinFullband,
      rtAudio8, rtAudio16, silk, silkNarrow, silkWide, siren, xmsRta,
      unknownFutureValue.
  averageAudioDegradation:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Average Network Mean Opinion Score degradation for stream. Represents how
      much the network loss and jitter has impacted the quality of received
      audio.
  averageAudioNetworkJitter:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Average jitter for the stream computed as specified in RFC 3550, denoted
      in ISO 8601 format. For example, 1 second is denoted as 'PT1S', where 'P'
      is the duration designator, 'T' is the time designator, and 'S' is the
      second designator.
    format: duration
    nullable: true
  averageBandwidthEstimate:
    type: number
    description: >-
      Average estimated bandwidth available between two endpoints in bits per
      second.
    format: int64
    nullable: true
  averageFreezeDuration:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: Average duration of the received freezing time in the video stream.
    format: duration
    nullable: true
  averageJitter:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Average jitter for the stream computed as specified in RFC 3550, denoted
      in ISO 8601 format. For example, 1 second is denoted as 'PT1S', where 'P'
      is the duration designator, 'T' is the time designator, and 'S' is the
      second designator.
    format: duration
    nullable: true
  averagePacketLossRate:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: Average packet loss rate for stream.
  averageRatioOfConcealedSamples:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Ratio of the number of audio frames with samples generated by packet loss
      concealment to the total number of audio frames.
  averageReceivedFrameRate:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Average frames per second received for all video streams computed over the
      duration of the session.
  averageRoundTripTime:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Average network propagation round-trip time computed as specified in RFC
      3550, denoted in ISO 8601 format. For example, 1 second is denoted as
      'PT1S', where 'P' is the duration designator, 'T' is the time designator,
      and 'S' is the second designator.
    format: duration
    nullable: true
  averageVideoFrameLossPercentage:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: Average percentage of video frames lost as displayed to the user.
  averageVideoFrameRate:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Average frames per second received for a video stream, computed over the
      duration of the session.
  averageVideoPacketLossRate:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Average fraction of packets lost, as specified in RFC 3550, computed over
      the duration of the session.
  endDateTime:
    pattern: >-
      ^[0-9]{4,}-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T([01][0-9]|2[0-3]):[0-5][0-9]:[0-5][0-9]([.][0-9]{1,12})?(Z|[+-][0-9][0-9]:[0-9][0-9])$
    type: string
    description: >-
      UTC time when the stream ended. The DateTimeOffset type represents date
      and time information using ISO 8601 format and is always in UTC time. For
      example, midnight UTC on Jan 1, 2014 is 2014-01-01T00:00:00Z. This field
      is only available for streams that use the SIP protocol.
    format: date-time
    nullable: true
  isAudioForwardErrorCorrectionUsed:
    type: boolean
    description: >-
      Indicates whether the forward error correction (FEC) was used at some
      point during the session. The default value is null.
    nullable: true
  lowFrameRateRatio:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: Fraction of the call where frame rate is less than 7.5 frames per second.
  lowVideoProcessingCapabilityRatio:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Fraction of the call that the client is running less than 70% expected
      video processing capability.
  maxAudioNetworkJitter:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Maximum of audio network jitter computed over each of the 20 second
      windows during the session, denoted in ISO 8601 format. For example, 1
      second is denoted as 'PT1S', where 'P' is the duration designator, 'T' is
      the time designator, and 'S' is the second designator.
    format: duration
    nullable: true
  maxJitter:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Maximum jitter for the stream computed as specified in RFC 3550, denoted
      in ISO 8601 format. For example, 1 second is denoted as 'PT1S', where 'P'
      is the duration designator, 'T' is the time designator, and 'S' is the
      second designator.
    format: duration
    nullable: true
  maxPacketLossRate:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: Maximum packet loss rate for the stream.
  maxRatioOfConcealedSamples:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: Maximum ratio of packets concealed by the healer.
  maxRoundTripTime:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Maximum network propagation round-trip time computed as specified in RFC
      3550, denoted in ISO 8601 format. For example, 1 second is denoted as
      'PT1S', where 'P' is the duration designator, 'T' is the time designator,
      and 'S' is the second designator.
    format: duration
    nullable: true
  packetUtilization:
    type: number
    description: Packet count for the stream.
    format: int64
    nullable: true
  postForwardErrorCorrectionPacketLossRate:
    oneOf:
      - type: number
        format: float
        nullable: true
      - type: string
        nullable: true
      - $ref: .\ReferenceNumeric.yaml
    description: >-
      Packet loss rate after FEC has been applied aggregated across all video
      streams and codecs.
  rmsFreezeDuration:
    pattern: ^-?P([0-9]+D)?(T([0-9]+H)?([0-9]+M)?([0-9]+([.][0-9]+)?S)?)?$
    type: string
    description: >-
      Average duration of the received freezing time in the video stream
      represented in root mean square.
    format: duration
    nullable: true
  startDateTime:
    pattern: >-
      ^[0-9]{4,}-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T([01][0-9]|2[0-3]):[0-5][0-9]:[0-5][0-9]([.][0-9]{1,12})?(Z|[+-][0-9][0-9]:[0-9][0-9])$
    type: string
    description: >-
      UTC time when the stream started. The DateTimeOffset type represents date
      and time information using ISO 8601 format and is always in UTC time. For
      example, midnight UTC on Jan 1, 2014 is 2014-01-01T00:00:00Z. This field
      is only available for streams that use the SIP protocol.
    format: date-time
    nullable: true
  streamDirection:
    $ref: .\microsoft.graph.callRecords.mediaStreamDirection.yaml
  streamId:
    type: string
    description: Unique identifier for the stream.
    nullable: true
  videoCodec:
    anyOf:
      - $ref: .\microsoft.graph.callRecords.videoCodec.yaml
      - type: object
        nullable: true
    description: >-
      Codec name used to encode video for transmission on the network. Possible
      values are: unknown, invalid, av1, h263, h264, h264s, h264uc, h265, rtvc1,
      rtVideo, xrtvc1, unknownFutureValue.
  wasMediaBypassed:
    type: boolean
    description: >-
      True if the media stream bypassed the Mediation Server and went straight
      between client and PSTN Gateway/PBX, false otherwise.
    nullable: true
  '@odata.type':
    type: string
